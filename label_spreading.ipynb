{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label propagation using CNN feature extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processor import test_loader, unlabeled_loader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.semi_supervised import LabelSpreading\n",
    "from sklearn.semi_supervised import LabelPropagation\n",
    "from models import CNNet\n",
    "from torch.utils.data import DataLoader\n",
    "from models import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = [transforms.RandomHorizontalFlip(p=1),\n",
    "     transforms.RandomRotation(degrees=(-10, 10), fill = (130, 130,130)),\n",
    "     transforms.RandomVerticalFlip(p=1),\n",
    "     transforms.RandomResizedCrop(size = (100,100), scale=(0.8, 1.0), ratio=(0.75, 1.3333333333333333), interpolation=2)]\n",
    "\n",
    "\n",
    "     \n",
    "transformation = transforms.Compose([\n",
    "transforms.Resize((100, 100)),\n",
    "transforms.RandomApply(ts, p=0.5),\n",
    "transforms.Grayscale(),\n",
    "transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = './semi_supervised_data/train_data'\n",
    "train_set = ImageFolder(\n",
    "\t    root=train_data_path,\n",
    "\t    transform = transformation)\n",
    "    \n",
    "train_loader = DataLoader(dataset=train_set, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started training ...\n",
      "the loss after processing this epoch is:  50.77671743184328\n",
      "the loss after processing this epoch is:  24.374547854065895\n",
      "the loss after processing this epoch is:  19.400708597153425\n",
      "the loss after processing this epoch is:  18.717636421322823\n",
      "the loss after processing this epoch is:  18.39981289766729\n",
      "the loss after processing this epoch is:  16.008887951262295\n",
      "the loss after processing this epoch is:  15.867740739136934\n",
      "the loss after processing this epoch is:  14.200564302504063\n",
      "the loss after processing this epoch is:  14.575025220867246\n",
      "the loss after processing this epoch is:  12.067018299363554\n",
      "Training completed.\n",
      "=*==*==*==*==*==*==*==*==*==*==*==*==*==*==*==*==*==*==*==*=\n"
     ]
    }
   ],
   "source": [
    "model = CNNet()\n",
    "model, loss = train_model(model, train_loader, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad(): \n",
    "    batch = next(iter(train_loader))\n",
    "    images, labels = batch\n",
    "    all_out = model.get_features(images)\n",
    "    all_labels = labels \n",
    "    \n",
    "    first_batch = len(images)\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        images, labels = batch \n",
    "        all_out = torch.cat((all_out, model.get_features(images)), 0)\n",
    "        all_labels = torch.cat((all_labels, labels), 0)\n",
    "\n",
    "    for batch in unlabeled_loader:\n",
    "        images, labels = batch\n",
    "        all_out = torch.cat((all_out, model.get_features(images)), 0)\n",
    "        unlabel = torch.tensor([-1]*len(labels))\n",
    "        all_labels = torch.cat((all_labels, unlabel), 0)\n",
    "\n",
    "all_out = all_out[first_batch:]\n",
    "all_labels = all_labels[first_batch:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14809, 50])\n",
      "torch.Size([14809])\n"
     ]
    }
   ],
   "source": [
    "print(all_out.shape)\n",
    "print(all_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images, test_labels = next(iter(test_loader))\n",
    "test_features = model.get_features(test_images)\n",
    "\n",
    "with torch.no_grad(): \n",
    "    for images, labels in test_loader:\n",
    "        test_features = torch.cat((test_features, model.get_features(images)), 0)\n",
    "        test_labels = torch.cat((test_labels, labels), 0)\n",
    "\n",
    "test_features = test_features[first_batch:]\n",
    "test_labels = test_labels[first_batch:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1848, 50])\n",
      "torch.Size([1848])\n"
     ]
    }
   ],
   "source": [
    "print(test_features.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8733766233766234"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_spr_model = LabelSpreading(max_iter = 50, kernel = 'knn', alpha = 0.01, n_neighbors = 100, tol = .001)\n",
    "\n",
    "label_spr_model.fit(all_out.numpy(), all_labels.numpy())\n",
    "\n",
    "label_spr_model.score(test_features.numpy(), test_labels.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
